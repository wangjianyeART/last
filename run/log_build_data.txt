Please check the above information for the configurations

train.py config: 
 {'AdamWeightDecay': {'beta1': 0.9,
 'beta2': 0.99,
 'decay_filter': ['layernorm', 'bias'],
 'end_learning_rate': 1e-10,
 'eps': 1e-06,
 'learning_rate': 0.002,
 'power': 1.0,
 'warmup_steps': 1000,
 'weight_decay': 1e-05},
 'batch_size': 20,
 'bidirectional': True,
 'build_data': True,
 'checkpoint_file': './checkpoint/lstm_crf.ckpt',
 'checkpoint_path': './checkpoint/',
 'checkpoint_url': '',
 'ckpt_file': './ckpt_lstm/lstm_crf.ckpt',
 'ckpt_path': 'lstm_crf-15_446.ckpt',
 'ckpt_save_path': '../ckpt_lstm_crf',
 'config_path': '/home/ma-user/work/models/research/nlp/lstm_crf/scripts/../default_config.yaml',
 'data_CoNLL_path': '../data/CoNLL2000',
 'data_path': './data',
 'data_url': '',
 'device_id': 1,
 'device_num': 1,
 'device_target': 'CPU',
 'dropout': 0.5,
 'embed_size': 300,
 'enable_graph_kernel': 'true',
 'enable_modelarts': False,
 'enable_profiling': False,
 'file_format': 'MINDIR',
 'file_name': 'lstm_crf',
 'glove_path': '../data/glove',
 'keep_checkpoint_max': 20,
 'label_dir': '',
 'load_path': './output/checkpoint_path',
 'num_epochs': 20,
 'num_hiddens': 320,
 'num_layers': 2,
 'optimizer': 'AdamWeightDecay',
 'output_path': './output/train',
 'pre_trained': '',
 'preprocess': 'True',
 'preprocess_path': './preprocess',
 'result_dir': './result_Files',
 'result_path': './preprocess_Result/',
 'train_url': ''}
load.... ../data/CoNLL2000/train.txt data
load.... ../data/CoNLL2000/test.txt data
Writing vocab......
- done. 17145 tokens
Writing vocab......
- done. 23 tokens
